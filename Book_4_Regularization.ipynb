{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task G\n",
    "- Train a neural net and prevent overÔ¨Åtting by regularization. \n",
    "- You can use any combination of regularizers we saw in class. \n",
    "- Use the train and test splits in the data do evaluate the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert class vectors to binary class matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "input_shape = (32, 32, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "#Lamda Layer\n",
    "model.add(Lambda(lambda x: x/256.-1.0, input_shape = (32,32,3))) \n",
    "\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "#Convolutional layers\n",
    "model.add( Conv2D(filters = 32, kernel_size = (3,3), padding = 'same', use_bias = 'true', activation = 'relu', input_shape =(32,32,3) ) )\n",
    "\n",
    "model.add( MaxPooling2D(pool_size=(2,2)) )\n",
    "\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add( Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', activation = 'tanh' ) )\n",
    "\n",
    "model.add( MaxPooling2D(pool_size=(2,2)) )\n",
    "\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add( Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', activation = 'relu' ) )\n",
    "\n",
    "#Converting data\n",
    "model.add(Flatten())  \n",
    "\n",
    "#Fully connected layers\n",
    "\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "#Finalizing and preparing the model for training\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Showing the summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 1.8629 - acc: 0.2986 - val_loss: 1.7390 - val_acc: 0.3563\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 1.5845 - acc: 0.4097 - val_loss: 1.5672 - val_acc: 0.4275\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 1.4981 - acc: 0.4491 - val_loss: 1.4537 - val_acc: 0.4549\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 1.4365 - acc: 0.4737 - val_loss: 1.4101 - val_acc: 0.4792\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 1.3941 - acc: 0.4912 - val_loss: 1.3846 - val_acc: 0.4863\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 1.3625 - acc: 0.5037 - val_loss: 1.4790 - val_acc: 0.4585\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 1.3323 - acc: 0.5180 - val_loss: 1.3747 - val_acc: 0.4943\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 1.3043 - acc: 0.5265 - val_loss: 1.3126 - val_acc: 0.5270\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 1.2721 - acc: 0.5399 - val_loss: 1.3033 - val_acc: 0.5208\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 1.2536 - acc: 0.5491 - val_loss: 1.2920 - val_acc: 0.5310\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 1.2339 - acc: 0.5537 - val_loss: 1.2582 - val_acc: 0.5475\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 1.2162 - acc: 0.5609 - val_loss: 1.3192 - val_acc: 0.5362\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 1.2021 - acc: 0.5677 - val_loss: 1.3115 - val_acc: 0.5367\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 1.1885 - acc: 0.5729 - val_loss: 1.2268 - val_acc: 0.5545\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 1.1752 - acc: 0.5780 - val_loss: 1.3377 - val_acc: 0.5327\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 1.1581 - acc: 0.5823 - val_loss: 1.2449 - val_acc: 0.5572\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 1.1476 - acc: 0.5865 - val_loss: 1.1747 - val_acc: 0.5752\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.1286 - acc: 0.5940 - val_loss: 1.2709 - val_acc: 0.5539\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 1.1281 - acc: 0.5951 - val_loss: 1.2786 - val_acc: 0.5511\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.1154 - acc: 0.5975 - val_loss: 1.2699 - val_acc: 0.5554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23c4b3eadd8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          verbose=1, #how progress is shown\n",
    "          validation_data=(x_test, y_test)\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
