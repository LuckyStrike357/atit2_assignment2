{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroal Network Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task F\n",
    "- Train a neural net and overï¬t it to cifar. \n",
    "- Don't use any regularization. \n",
    "- Don't use my crappy implementation, but use keras. Use the train and test splits in the data do evaluate the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert class vectors to binary class matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices -> one hot \n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                262208    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 319,178\n",
      "Trainable params: 319,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Creating a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "#Convolutional layers\n",
    "model.add( Conv2D(filters = 32, kernel_size = (3,3), padding = 'same', use_bias = 'true', activation = 'relu', input_shape =(32,32,3) ) )\n",
    "\n",
    "model.add( MaxPooling2D(pool_size=(2,2)) )\n",
    "\n",
    "model.add( Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', activation = 'tanh' ) )\n",
    "\n",
    "model.add( MaxPooling2D(pool_size=(2,2)) )\n",
    "\n",
    "model.add( Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', activation = 'relu' ) )\n",
    "\n",
    "#Converting data\n",
    "model.add(Flatten())  \n",
    "\n",
    "#Fully connected layers\n",
    "\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "#Finalizing and preparing the model for training\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Showing the summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 42s 838us/step - loss: 1.7366 - acc: 0.3759\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 43s 860us/step - loss: 1.3283 - acc: 0.5310\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 44s 878us/step - loss: 1.1681 - acc: 0.5918\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 47s 947us/step - loss: 1.0583 - acc: 0.6302\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 47s 931us/step - loss: 0.9876 - acc: 0.6569\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 48s 968us/step - loss: 0.9364 - acc: 0.6732\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 46s 929us/step - loss: 0.8786 - acc: 0.6944\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 44s 885us/step - loss: 0.8342 - acc: 0.7119\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 44s 890us/step - loss: 0.7960 - acc: 0.7237\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 44s 885us/step - loss: 0.7585 - acc: 0.7383\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 44s 880us/step - loss: 0.7248 - acc: 0.7493\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 45s 897us/step - loss: 0.6942 - acc: 0.7608\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 46s 925us/step - loss: 0.6728 - acc: 0.7665\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 45s 898us/step - loss: 0.6444 - acc: 0.7754\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 45s 909us/step - loss: 0.6245 - acc: 0.7834\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 46s 916us/step - loss: 0.5918 - acc: 0.7953\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 47s 941us/step - loss: 0.5762 - acc: 0.8012\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 47s 949us/step - loss: 0.5479 - acc: 0.8091\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 46s 923us/step - loss: 0.5202 - acc: 0.8213\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 49s 971us/step - loss: 0.4971 - acc: 0.8277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28579439fd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=500,\n",
    "          epochs=20,\n",
    "          verbose=1, #how progress is shown\n",
    "         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/17\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.5584 - acc: 0.8028 - val_loss: 0.8563 - val_acc: 0.7234\n",
      "Epoch 2/17\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.5144 - acc: 0.8185 - val_loss: 0.8606 - val_acc: 0.7245\n",
      "Epoch 3/17\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.4835 - acc: 0.8291 - val_loss: 0.9100 - val_acc: 0.7154\n",
      "Epoch 4/17\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.4432 - acc: 0.8446 - val_loss: 0.8659 - val_acc: 0.7288\n",
      "Epoch 5/17\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.4079 - acc: 0.8563 - val_loss: 0.9077 - val_acc: 0.7273\n",
      "Epoch 6/17\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.3788 - acc: 0.8667 - val_loss: 0.9216 - val_acc: 0.7268\n",
      "Epoch 7/17\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.3501 - acc: 0.8768 - val_loss: 0.9694 - val_acc: 0.7196\n",
      "Epoch 8/17\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.3199 - acc: 0.8881 - val_loss: 0.9592 - val_acc: 0.7259\n",
      "Epoch 9/17\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.3008 - acc: 0.8943 - val_loss: 1.0042 - val_acc: 0.7236\n",
      "Epoch 10/17\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.2769 - acc: 0.9019 - val_loss: 1.0581 - val_acc: 0.7218\n",
      "Epoch 11/17\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.2552 - acc: 0.9119 - val_loss: 1.0529 - val_acc: 0.7220\n",
      "Epoch 12/17\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.2342 - acc: 0.9197 - val_loss: 1.0975 - val_acc: 0.7242\n",
      "Epoch 13/17\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.2078 - acc: 0.9283 - val_loss: 1.1666 - val_acc: 0.7155\n",
      "Epoch 14/17\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.1788 - acc: 0.9391 - val_loss: 1.2036 - val_acc: 0.7258\n",
      "Epoch 15/17\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.1680 - acc: 0.9423 - val_loss: 1.2981 - val_acc: 0.7141\n",
      "Epoch 16/17\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.1602 - acc: 0.9442 - val_loss: 1.3546 - val_acc: 0.7209\n",
      "Epoch 17/17\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.1453 - acc: 0.9500 - val_loss: 1.3185 - val_acc: 0.7212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x285095dec18>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=250,\n",
    "          epochs=17,\n",
    "          verbose=1, #how progress is shown\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 43s 870us/step - loss: 0.0811 - acc: 0.9780 - val_loss: 1.3455 - val_acc: 0.7243\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 45s 895us/step - loss: 0.0520 - acc: 0.9908 - val_loss: 1.3583 - val_acc: 0.7318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2857fd847f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=1028,\n",
    "          epochs=5,\n",
    "          verbose=1, #how progress is shown\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.3582566591262817\n",
      "Test accuracy: 0.7318\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "This is our result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
